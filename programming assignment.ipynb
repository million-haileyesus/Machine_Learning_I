{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77ecfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noill\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8d89d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c4557",
   "metadata": {},
   "source": [
    "# Traditional Features Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcad6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image():\n",
    "    path = \"../DataSet/Training/Normal\"\n",
    "    folders = os.listdir(path)\n",
    "    no_of_images = []\n",
    "    for folder in folders:\n",
    "        files = [f for f in os.listdir(f\"{path}/{folder}\") if os.path.isfile(os.path.join(f\"../Resized/{folder}\", f))]\n",
    "        no_of_images.append(len(files))\n",
    "        \n",
    "    collection = {}\n",
    "    for folder, count in zip(folders, no_of_images):\n",
    "        all_files = os.listdir(f\"{path}/{folder}\")\n",
    "        collection[folder] = all_files\n",
    "        \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae65a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_collections = get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef3473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(path, new_path, folder, image):\n",
    "    path = path + \"/\" + folder + \"/\" + image\n",
    "    loaded_image = cv.imread(path)\n",
    "    gray = cv.cvtColor(loaded_image, cv.COLOR_BGR2GRAY)\n",
    "    sift = cv.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray, None)\n",
    "    img = cv.drawKeypoints(gray, kp, loaded_image)\n",
    "    new_path = new_path + \"/\" + folder\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)\n",
    "    new_path = new_path + \"/\" + image\n",
    "    cv.imwrite(new_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe77cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features():\n",
    "    path = \"../DataSet/Training/Normal\"\n",
    "    new_path = \"../DataSet/Training/Feature Extracted\"\n",
    "    folders = []\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    for folder, images in image_collections.items():\n",
    "        for image in images:\n",
    "            folders.append(folder)\n",
    "            feature_extraction(path, new_path, folder, image)\n",
    "    \n",
    "    return folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f888dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08dd8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    training_images = glob.glob(\"../DataSet/Training/Feature Extracted/*/*\")\n",
    "    testing_images = glob.glob(\"../DataSet/Testing/*/*\")\n",
    "        \n",
    "    return training_images, testing_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f1ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img, testing_img = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a522fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_target(images):\n",
    "    targets = {f: 0 for f in folders}  \n",
    "    for i, a in enumerate(images):\n",
    "        b = a.split(\"\\\\\")\n",
    "        targets[b[1]] += 1\n",
    "        \n",
    "    target_images = []\n",
    "    for i, (k, v) in enumerate(targets.items()):\n",
    "        target_images = np.concatenate((target_images, np.full(v, i)), axis = 0) \n",
    "        \n",
    "    return target_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "644deed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images_target = dataset_target(training_img)\n",
    "testing_images_target = dataset_target(testing_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b49aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels(images):\n",
    "    combine = []\n",
    "    for img in images:\n",
    "        loaded_image = cv.imread(img)\n",
    "        combine.append(loaded_image)\n",
    "    \n",
    "    return combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde96a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = get_pixels(training_img)\n",
    "testing_images = get_pixels(testing_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd001b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_clustering(X):\n",
    "    kmeans = KMeans(n_clusters=100, random_state=0, init=\"random\", n_init=\"auto\").fit(X)\n",
    "    \n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69e849ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_reduction(features):\n",
    "    pca = PCA(n_components=2)\n",
    "    transformed_data = pca.fit_transform(features)\n",
    "    \n",
    "    for i in range(4):\n",
    "        c = np.flatnonzero(class_labels == i)\n",
    "        plt.scatter(transformed_data[c, 0], transformed_data[c, 1])\n",
    "    plt.show()\n",
    "    \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8e6bc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ffb18",
   "metadata": {},
   "source": [
    "# Traditional Machine Learnign model - Support Vecotr Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3006029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(kernel_type=\"linear\"):\n",
    "    num_samples, height, width, channels = np.array(training_images).shape\n",
    "    X_train = np.array(training_images).reshape(num_samples, height * width * channels)\n",
    "    \n",
    "    num_samples, height, width, channels = np.array(testing_images).shape\n",
    "    X_test = np.array(testing_images).reshape(num_samples, height * width * channels) \n",
    "    \n",
    "    scores = []\n",
    "    parameters = [0.001, 0.1, 1.0, 10, 100]\n",
    "    for c in parameters:\n",
    "        svc = SVC(kernel=kernel_type, C=c, random_state=42)\n",
    "        svc.fit(X_train, training_images_target)\n",
    "        scores.append(1 - svc.score(X_test, testing_images_target))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062b5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = train_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe09f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svm_performance():\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef86c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_for_different_kernels():\n",
    "    kernel_type = \"rbf\", \"poly\", \"sigmoid\"\n",
    "    for kernel in kernel_type:\n",
    "        train_svm(kernel_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b593f82",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9498655",
   "metadata": {},
   "source": [
    "# Deep Learning - Training a Simple Convolution Neural Network Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c93a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_classifier():\n",
    "    num_nodes = 10\n",
    "    input_shape = (100, 100, 1)\n",
    "    \n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape), \n",
    "        layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)), \n",
    "        layers.Flatten(), \n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(num_nodes, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = images_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    batch_size = 128\n",
    "    num_epochs = 30\n",
    "    \n",
    "    X_train = np.array(training_images)\n",
    "    y_train = np.array(training_images_target)\n",
    "    X_test = np.array(testing_images)\n",
    "    y_test = np.array(testing_images_target)\n",
    "    \n",
    "    print(X_train.shape, X_test.shape)\n",
    "    X_train = X_train.astype(\"float32\") / 255\n",
    "    X_test = X_test.astype(\"float32\") / 255\n",
    "    # Make sure images have shape (28, 28, 1)\n",
    "    X_train = np.expand_dims(X_train, -1)\n",
    "    X_test = np.expand_dims(X_test, -1)\n",
    "    print(\"x_train shape:\", X_train.shape)\n",
    "    print(X_train.shape[0], \"train samples\")\n",
    "    print(X_test.shape[0], \"test samples\")\n",
    "    \n",
    "    y_train = to_categorical(y_train, num_classes=10)\n",
    "    y_test = to_categorical(y_test, num_classes=10)\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.2)\n",
    "    \n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f01d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation():\n",
    "    model, history, X_test, y_test = train_model()\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"\\n\\nTest loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1035be",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936a927",
   "metadata": {},
   "source": [
    "# Transfer Learning via Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16908783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_read():\n",
    "    data_transforms = v2.Compose([\n",
    "        v2.Resize((224,224)),   \n",
    "        v2.ToTensor(),\n",
    "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  \n",
    "    ])\n",
    "\n",
    "    test_classes = []\n",
    "    for image in testing_images:\n",
    "        transformed_images = data_transforms(image)\n",
    "        test_classes.append(transformed_images)\n",
    "    \n",
    "    return test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = preprocessing_read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f18509",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a67a15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracy = alexnet(test_classes)    \n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
