{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77ecfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noill\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8d89d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c4557",
   "metadata": {},
   "source": [
    "# Traditional Features Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcad6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image():\n",
    "    path = \"../DataSet/Training/Normal\"\n",
    "    folders = os.listdir(path)\n",
    "    no_of_images = []\n",
    "    for folder in folders:\n",
    "        files = [f for f in os.listdir(f\"{path}/{folder}\") if os.path.isfile(os.path.join(f\"../Resized/{folder}\", f))]\n",
    "        no_of_images.append(len(files))\n",
    "        \n",
    "    collection = {}\n",
    "    for folder, count in zip(folders, no_of_images):\n",
    "        all_files = os.listdir(f\"{path}/{folder}\")\n",
    "        collection[folder] = all_files\n",
    "        \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae65a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_collections = get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef3473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(path, new_path, folder, image):\n",
    "    path = path + \"/\" + folder + \"/\" + image\n",
    "    loaded_image = cv.imread(path)\n",
    "    gray = cv.cvtColor(loaded_image, cv.COLOR_BGR2GRAY)\n",
    "    sift = cv.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray, None)\n",
    "    img = cv.drawKeypoints(gray, kp, loaded_image)\n",
    "    new_path = new_path + \"/\" + folder\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)\n",
    "    new_path = new_path + \"/\" + image\n",
    "    cv.imwrite(new_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe77cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features():\n",
    "    new_path = \"../DataSet/Training/Feature Extracted\"\n",
    "    path = \"../DataSet/Training/Normal\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    for folder, images in image_collections.items():\n",
    "        for image in images:\n",
    "            feature_extraction(path, new_path, folder, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f888dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08dd8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = glob.glob(\"../DataSet/Training/Feature Extracted/*/*\")\n",
    "testing_images = glob.glob(\"../DataSet/Testing/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63b49aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels(images):\n",
    "    combine = []\n",
    "    for img in images:\n",
    "        loaded_image = cv.imread(img)\n",
    "        combine.append(loaded_image)\n",
    "    \n",
    "    return combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bde96a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = get_pixels(training_images)\n",
    "testing_images = get_pixels(testing_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1f63f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = np.array(training_images)\n",
    "testing_images = np.array(testing_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd001b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_clustering(X):\n",
    "    kmeans = KMeans(n_clusters=100, random_state=0, init=\"random\", n_init=\"auto\").fit(X)\n",
    "    \n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e849ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_reduction(features):\n",
    "    pca = PCA(n_components=2)\n",
    "    transformed_data = pca.fit_transform(features)\n",
    "    \n",
    "    for i in range(4):\n",
    "        c = np.flatnonzero(class_labels == i)\n",
    "        plt.scatter(transformed_data[c, 0], transformed_data[c, 1])\n",
    "    plt.show()\n",
    "    \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8e6bc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ffb18",
   "metadata": {},
   "source": [
    "# Traditional Machine Learnign model - Support Vecotr Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(kernel_type=\"linear\"):\n",
    "    parameters = [0.001, 0.1, 1.0, 10, 100]\n",
    "    \n",
    "    for c in parameters:\n",
    "        svc = SVC(kernel=kernel_type, C=c, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe09f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svm_performance():\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef86c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_for_different_kernels():\n",
    "    kernel_type = \"rbf\", \"poly\", \"sigmoid\"\n",
    "    for kernel in kernel_type:\n",
    "        train_svm(kernel_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b593f82",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9498655",
   "metadata": {},
   "source": [
    "# Deep Learning - Training a Simple Convolution Neural Network Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c93a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_classifier():\n",
    "    num_nodes = 10\n",
    "    input_shape = (100, 100, 1)\n",
    "    \n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape), \n",
    "        layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)), \n",
    "        layers.Flatten(), \n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(num_nodes, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e5f5c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 98, 98, 8)         80        \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 96, 96, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 48, 48, 8)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                294928    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 296034 (1.13 MB)\n",
      "Trainable params: 296034 (1.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = images_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbc2f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    batch_size = 128\n",
    "    num_epochs = 30\n",
    "    X_train, y_train, X_test, y_test = train_test_split(training_images, testing_images, test_size=0.2)\n",
    "    \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 100, 100, 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 100, 100, 1))\n",
    "    \n",
    "    y_train = to_categorical(y_train, num_classes=10)\n",
    "    y_test = to_categorical(y_test, num_classes=10)\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.2)\n",
    "    \n",
    "    return model, history, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5f01d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation():\n",
    "    model, history, X_test, y_test = train_model()\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"\\n\\nTest loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8b3b139",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4582, 1538]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m, in \u001b[0;36mmodel_evaluation\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_evaluation\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     model, history, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[43], line 4\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[0;32m      3\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m----> 4\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(X_train, (X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      7\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(X_test, (X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2646\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2646\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2648\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2649\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2650\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2651\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:453\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    452\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 453\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4582, 1538]"
     ]
    }
   ],
   "source": [
    "model = model_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1035be",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936a927",
   "metadata": {},
   "source": [
    "# Transfer Learning via Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d43b08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fe2e458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
